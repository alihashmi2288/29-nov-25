"use strict";(globalThis.webpackChunkbook_project=globalThis.webpackChunkbook_project||[]).push([[7686],{1918:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>o,toc:()=>d});const o=JSON.parse('{"id":"preface","title":"Preface","description":"Welcome to \\"Physical AI & Humanoid Robotics\\"! This book is designed to be a comprehensive guide for students and developers interested in the exciting field of embodied intelligence. Our goal is to bridge the gap between the digital world of AI and the physical world of robotics, equipping you with the knowledge and skills to build and command humanoid robots.","source":"@site/docs/preface.md","sourceDirName":".","slug":"/preface","permalink":"/29-nov-25/docs/preface","draft":false,"unlisted":false,"editUrl":"https://github.com/alihashmi/book-project/tree/main/docs/preface.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Tutorial Intro","permalink":"/29-nov-25/docs/intro"},"next":{"title":"Create a Page","permalink":"/29-nov-25/docs/tutorial-basics/create-a-page"}}');var t=i(4848),s=i(8453);const r={},a="Preface",l={},d=[{value:"Modules Overview",id:"modules-overview",level:2},{value:"Module 1: The Robotic Nervous System (ROS 2)",id:"module-1-the-robotic-nervous-system-ros-2",level:3},{value:"Module 2: The Digital Twin (Gazebo &amp; Unity)",id:"module-2-the-digital-twin-gazebo--unity",level:3},{value:"Module 3: The AI-Robot Brain (NVIDIA Isaac\u2122)",id:"module-3-the-ai-robot-brain-nvidia-isaac",level:3},{value:"Module 4: Vision-Language-Action (VLA)",id:"module-4-vision-language-action-vla",level:3}];function c(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"preface",children:"Preface"})}),"\n",(0,t.jsx)(n.p,{children:'Welcome to "Physical AI & Humanoid Robotics"! This book is designed to be a comprehensive guide for students and developers interested in the exciting field of embodied intelligence. Our goal is to bridge the gap between the digital world of AI and the physical world of robotics, equipping you with the knowledge and skills to build and command humanoid robots.'}),"\n",(0,t.jsx)(n.p,{children:"Throughout this book, we will explore the core technologies and concepts that power modern robotics, from the underlying software architecture to advanced AI-driven behaviors. The book is divided into four modules, each focusing on a critical aspect of physical AI."}),"\n",(0,t.jsx)(n.h2,{id:"modules-overview",children:"Modules Overview"}),"\n",(0,t.jsx)(n.h3,{id:"module-1-the-robotic-nervous-system-ros-2",children:"Module 1: The Robotic Nervous System (ROS 2)"}),"\n",(0,t.jsx)(n.p,{children:"This module introduces you to the Robot Operating System (ROS 2), the middleware that acts as the nervous system for our robots. You will learn about:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Chapter 1:"})," Introduction to ROS 2: Core Concepts and Architecture"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Chapter 2:"})," ROS 2 Nodes and Topics: The Communication Backbone"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Chapter 3:"})," ROS 2 Services and Actions: For Request/Response and Long-Running Tasks"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Chapter 4:"})," Working with URDF: Describing a Humanoid Robot's Physical Structure"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Chapter 5:"})," Bridging Python Agents to ROS Controllers with ",(0,t.jsx)(n.code,{children:"rclpy"})]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"module-2-the-digital-twin-gazebo--unity",children:"Module 2: The Digital Twin (Gazebo & Unity)"}),"\n",(0,t.jsx)(n.p,{children:"In this module, we dive into the world of simulation, creating digital twins of our robots and their environments. We will cover:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Chapter 1:"})," Introduction to Robotics Simulation: The Role of Digital Twins"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Chapter 2:"})," Building a World in Gazebo: Simulating Physics, Gravity, and Collisions"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Chapter 3:"})," Simulating Sensors: Cameras, LiDAR, and IMUs"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Chapter 4:"})," High-Fidelity Rendering and Human-Robot Interaction in Unity"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Chapter 5:"})," Integrating Gazebo and Unity with ROS 2"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"module-3-the-ai-robot-brain-nvidia-isaac",children:"Module 3: The AI-Robot Brain (NVIDIA Isaac\u2122)"}),"\n",(0,t.jsx)(n.p,{children:"This module focuses on the AI that powers our robots' brains, with a focus on NVIDIA's powerful Isaac platform. You will learn about:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Chapter 1:"})," Introduction to NVIDIA Isaac for Advanced Robotics"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Chapter 2:"})," Isaac Sim: Photorealistic Simulation and Synthetic Data Generation"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Chapter 3:"})," Isaac ROS: Hardware-Accelerated Perception"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Chapter 4:"})," Visual SLAM (VSLAM) and Navigation with Isaac ROS"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Chapter 5:"})," Advanced Path Planning for Humanoids with Nav2"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"module-4-vision-language-action-vla",children:"Module 4: Vision-Language-Action (VLA)"}),"\n",(0,t.jsx)(n.p,{children:"In the final module, we explore the cutting-edge field of Vision-Language-Action models, enabling our robots to understand and interact with the world in a more human-like way. We will cover:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Chapter 1:"})," The Convergence of Large Language Models and Robotics"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Chapter 2:"})," From Voice to Action: Implementing Voice Commands"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Chapter 3:"})," Cognitive Planning: Using LLMs to Decompose High-Level Commands"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Chapter 4:"})," Integrating Vision-Language-Action Models with ROS 2 for Robotic Control"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Chapter 5:"})," Building an End-to-End VLA Application"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"By the end of this book, you will have the foundational knowledge to design, simulate, and deploy your own humanoid robots, ready to tackle the challenges of the physical world. Let's get started!"})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>a});var o=i(6540);const t={},s=o.createContext(t);function r(e){const n=o.useContext(s);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),o.createElement(s.Provider,{value:n},e.children)}}}]);